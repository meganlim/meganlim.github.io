<html>
<head>
  <title>Metrics</title>
  <link rel="stylesheet" type="text/css" href="nasa.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
</head>

<body>
  <h3 style = "padding-top:30px; padding-bottom:20px">Metrics</h3>
  <div>

    The goal of Metrics is to evaluate Prognostics performance.<br><br>

    Significance: lack of standard definitions that can compare performance across different algorithms<br><br>

    Goal: create standardized methodology for performance evaluation (metrics)<br><br>

    Difficulties in Creating Standard Definition: varied end-user requirements, time scales, available information, domain dynamics,
    performance tracking: trade-offs arise as time evolves<br>
    <ul>
      <li>Acausality: requires information about future events in order to make predictions.  Utilizing past history
      adds to the uncertainty</li>
      <li>Run to Failure Paradox: Taking action to prevent predicted failure eliminates the chance of validating whether the failure actually occurs.
        Run to Failure experiments are also very expensive and time consuming, may be worth to just deal with actual failure.</li>
      <li>Prognostic Uncertainty: as embodied in statistical distributions</li>
    </ul>

    Benefits: communicate and disseminate results, improve decision making, feedback to improve prognostic algorithms<br><br>

    Impact: How will prognostic evaluation be incorporated into the health management decision making process?<br><br>

    Application: Aerospace industry, NASA's Integrated Vehicle Health Management <br><br>

    Useful Terminology (Prognostic Framework):<br>
    <ul>
      <li>PDF = Probability Density Function</li>
      <li>UUT = Unit Under Test</li>
      <li>PA = Prognostic Algorithm</li>
      <li>PHM = Prognostic Health Management</li>
      <li>RUL = Remaining Useful Life</li>
      <li>EoL = End of Life</li>
      <li>EoP = End of Prediction, time index of last prediction before EoL</li>
      <li>EoUP = End of Useful Predictions, time index where RUL is no longer useful to update</li>
      <li>HI = Health Index</li>
      <li>PoF = Probability of Failure</li>
      <li>FT = Failure Threshold, UUT is no longer usable</li>
      <li>RtF = Run to Failure, allow system to fail</li>
      <li>ROI = Return On Investment</li>
      <li>F = time index when fault becomes detectable</li>
      <li>D = time index when fault is detected</li>
      <li>P = time index of first prognostic prediction</li>
      <li>PH = Prognostic Horizon</li>
    </ul><br>

    Sources of Error: model inaccuracy, data noise, observer faults<br><br>

    Considerations: logistics, saftey, reliability, mission criticality, economic viability- estimate cost savings expected from prognostic algorithm deployment<br><br>

    Process: Diagnostic algorithm (independent of prognostics) detects fault --> triggers PA --> PA predicts growth of that fault<br><br>

    Statistical distributions are effective ways of encapsulating the uncertainties in prognostic predictions.  Mean and
    variance are good measurements for Normal distributions when there are fewer deviations. Another method is to define
    a permittable error around a specific point and integrate between the bounds under the curve to find total probability.
    (A summation would be used instead for the discrete case). Another method involves the linear combination of Gaussians
    with length of each's error bars as weights.<br><br>

    Asymmetry in probability distributions arises from uneven preference of earlier and later predictions.
    Earlier predictions have less information about the system and must predict farther from their current state. Accumulating
    data over time is continually fed into succeeding distributions making analysis of algorithm improvement also important.<br><br>

    Prognostic Metrics:
    <ul>
      <li> Prognostic Horizon: whether algorithm predicts within an error margin(α)</li>
        math: EoL(time index) - first prediction entering boundary (time index)
      <li>α-λ Performance: whether algorithm remains within cone of accuracy at a specific time(λ)</li>
      binary metric: outputs either 1 or 0<br>
      α-λ accuracy = 1 if probability mass > β (minimal acceptable probability), = 0 otherwise <br>
      λ = [0,1]<br>
      t(sub)p = time index of beginning prediction<br>
      t(sub)EoL = time index of End of Life<br>
      t(sub)λ = specific time index
      <li>Relative Accuracy: percent error of RUL prediction</li>
      math:
      <li>Convergence: rate metrics improve with time</li>
      math: distance between origin and centroid of area under curve for a metric<br>
      relation: lower distance = faster convergence
    </ul>
    <br>

      <h2>References</h2>
      Saxena, A., Celaya, J., Saha, B., Saha, S., & Goebel, K. Metrics for Offline Evaluation of Prognostic Performance. International Journal of Prognostics and Health Management, Vol. 1, No. 1, 21 pages, 2010.<br><br>

</div>
</body>
</html>
